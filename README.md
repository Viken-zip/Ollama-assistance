# Ollama assistance
Ollama Assistance is a desktop GUI project for easy-to-use local LLMs using Ollama because it is easy to implement in projects.
M is for activating STT. works without using STT to, i recomend 8GB VRAM GPU for this to work.

- this project is in a working state ATM but you need to install Ollama and python 3.11 peferd and add path to the DLL and DLLs in settings -> config
- for experimental STT to work you need the correct libraries for it to work, but i have yet to make requirements.txt for more user frendly sulution for that.
- chat history is saved in a .txt file in your AppData/Local/OllamaAssistance/ folder
