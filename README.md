# Ollama assistance
Ollama Assistance is a desktop GUI project for easy-to-use local LLMs using Ollama because it is easy to implement in projects.

Note: this only works on Windows for now, sorry Linux and Mac users.
Ctrl + M is for activating STT. works without using STT to, i recomend 8GB VRAM GPU for this to work.

- this project is in a working state ATM but you need to install Ollama and python 3.11 peferd and add path to the DLL and DLLs in settings -> config
- for the project to work as intended you need to run the requirements.txt
- chat history is saved in a .txt file in AppData/Local/OllamaAssistance/ folder
- config file is also saved in a .json file in the AppData/Local/OllamaAssistance/ folder
